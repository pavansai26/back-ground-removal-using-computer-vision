{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#== Parameters =======================================================================\n",
    "BLUR = 21\n",
    "CANNY_THRESH_1 = 10\n",
    "CANNY_THRESH_2 = 200\n",
    "MASK_DILATE_ITER = 10\n",
    "MASK_ERODE_ITER = 10\n",
    "MASK_COLOR = (0.0,0.0,1.0) # In BGR format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('C:/Users/lenovo/Downloads/WhatsApp Image 2020-04-18 at 18.18.57.jpeg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(gray, CANNY_THRESH_1, CANNY_THRESH_2)\n",
    "edges = cv2.dilate(edges, None)\n",
    "edges = cv2.erode(edges, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Find contours in edges, sort by area ---------------------------------------------\n",
    "contour_info = []\n",
    "_, contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "# Previously, for a previous version of cv2, this line was: \n",
    "#  contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "# Thanks to notes from commenters, I've updated the code but left this note\n",
    "for c in contours:\n",
    "    contour_info.append((\n",
    "        c,\n",
    "        cv2.isContourConvex(c),\n",
    "        cv2.contourArea(c),\n",
    "    ))\n",
    "contour_info = sorted(contour_info, key=lambda c: c[2], reverse=True)\n",
    "max_contour = contour_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- Create empty mask, draw filled polygon on it corresponding to largest contour ----\n",
    "# Mask is black, polygon is white\n",
    "mask = np.zeros(edges.shape)\n",
    "cv2.fillConvexPoly(mask, max_contour[0], (255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Smooth mask, then blur it --------------------------------------------------------\n",
    "mask = cv2.dilate(mask, None, iterations=MASK_DILATE_ITER)\n",
    "mask = cv2.erode(mask, None, iterations=MASK_ERODE_ITER)\n",
    "mask = cv2.GaussianBlur(mask, (BLUR, BLUR), 0)\n",
    "#mask_stack = np.dstack([mask]*3)    # Create 3-channel alpha mask\n",
    "\n",
    "#-- Blend masked img into MASK_COLOR background --------------------------------------\n",
    "#mask_stack  = mask_stack.astype('float32') / 255.0          # Use float matrices, \n",
    "#img         = img.astype('float32') / 255.0                 #  for easy blending\n",
    "\n",
    "#masked = (mask_stack * img) + ((1-mask_stack) * MASK_COLOR) # Blend\n",
    "#masked = (masked * 255).astype('uint8')                     # Convert back to 8-bit \n",
    "\n",
    "#cv2.imshow('img', masked)\n",
    "#cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\merge.cpp:458: error: (-215:Assertion failed) mv[i].size == mv[0].size && mv[i].depth() == depth in function 'cv::merge'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-16f3abcf5952>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# merge with mask got on one of a previous steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimg_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_red\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_green\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_blue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# show on screen (optional in jupiter)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\merge.cpp:458: error: (-215:Assertion failed) mv[i].size == mv[0].size && mv[i].depth() == depth in function 'cv::merge'\n"
     ]
    }
   ],
   "source": [
    "# split image into channels\n",
    "c_red, c_green, c_blue = cv2.split(img)\n",
    "\n",
    "# merge with mask got on one of a previous steps\n",
    "img_a = cv2.merge((c_red, c_green, c_blue, mask.astype('float32') / 255.0))\n",
    "\n",
    "# show on screen (optional in jupiter)\n",
    "%matplotlib inline\n",
    "plt.imshow(img_a)\n",
    "plt.show()\n",
    "\n",
    "# save to disk\n",
    "cv2.imwrite('girl_1.png', img_a*255)\n",
    "\n",
    "# or the same using plt\n",
    "plt.imsave('girl_2.png', img_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
